{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DISTIL_Example_OOD_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOkAr6RnQ2BJ"
      },
      "source": [
        "# DISTIL Usage Example: CIFAR-10 with Out-of-Distribution Points\n",
        "\n",
        "Occasionally, a labeled dataset may not have enough data to yield good model performance. The easiest fix is to add more data by selecting and labeling unlabeled instances from a large pool of unlabeled data. However, the relative ease of acquiring unlabeled data in certain instances makes it very easy to accrue some out-of-distribution (OOD) examples. Inadvertently selecting OOD points from the unlabeled data constitutes a waste of effort since these points are not added to the labeled dataset. So, how do we select examples from the unlabeled pool that are not OOD? Here, we show how to use DISTIL's implementation of [SIMILAR](https://arxiv.org/abs/2107.00717) to avoid selecting OOD data."
      ],
      "id": "lOkAr6RnQ2BJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ibaupa-l2T_"
      },
      "source": [
        "# Preparation"
      ],
      "id": "-Ibaupa-l2T_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViAJ7rawfp53"
      },
      "source": [
        "## Installation and Imports"
      ],
      "id": "ViAJ7rawfp53"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmhefeJQfqKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc99f7f-03c0-40c0-dacb-c33ab0c2152e"
      },
      "source": [
        "# Get DISTIL\n",
        "!git clone https://github.com/decile-team/distil.git\n",
        "!pip install -r distil/requirements/requirements.txt\n",
        "\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, Subset, ConcatDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import cifar\n",
        "\n",
        "sys.path.append('distil/')\n",
        "from distil.active_learning_strategies import SCMI, GLISTER, BADGE, EntropySampling, RandomSampling   # All active learning strategies showcased in this example\n",
        "from distil.utils.models.resnet import ResNet18                                                       # The model used in our image classification example\n",
        "from distil.utils.train_helper import data_train                                                      # A utility training class provided by DISTIL\n",
        "from distil.utils.utils import LabeledToUnlabeledDataset                                              # A utility wrapper class that removes labels from labeled PyTorch dataset objects"
      ],
      "id": "nmhefeJQfqKb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'distil' already exists and is not an empty directory.\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
            "Requirement already satisfied: sphinxcontrib-bibtex>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: multipledispatch==0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: scikit-learn==0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 6)) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 8)) (0.51.2)\n",
            "Requirement already satisfied: submodlib in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 12)) (1.1.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 13)) (0.11.1+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch==0.6.0->-r distil/requirements/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->-r distil/requirements/requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->-r distil/requirements/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: pybtex-docutils>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: docutils>=0.8 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (0.17.1)\n",
            "Requirement already satisfied: Sphinx>=2.1 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (4.3.1)\n",
            "Requirement already satisfied: pybtex>=0.20 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r distil/requirements/requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->-r distil/requirements/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->-r distil/requirements/requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from pybtex>=0.20->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.7/dist-packages (from pybtex>=0.20->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.11.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from submodlib->-r distil/requirements/requirements.txt (line 11)) (0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r distil/requirements/requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r distil/requirements/requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4oIq8U7f6Dw"
      },
      "source": [
        "## Preparing CIFAR-10 with OOD Data\n",
        "\n",
        "The CIFAR10 dataset contains 60,000 32x32 color images in 10 different classes.The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. The training set contains 50,000 images, and the test set contains 10,000 images. Here, we do a simple setup of the CIFAR10 dataset that we will use in this example. More importantly, we define a split on CIFAR10's training set into an initial labeled seed set and an unlabeled set. For the purposes of this example, we will treat the non-animal classes (0, 1, 8, and 9) as OOD classes."
      ],
      "id": "v4oIq8U7f6Dw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaaAWcsKf6Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e1e727-b66a-4506-e49d-7c5a4e14cde6"
      },
      "source": [
        "# Define the name of the dataset and the path that PyTorch should use when downloading the data\n",
        "data_set_name = 'CIFAR10'\n",
        "download_path = '.'\n",
        "\n",
        "# Define the number of classes in our modified CIFAR10, which is 6. We also define our ID classes\n",
        "nclasses = 6\n",
        "id_classes = [2,3,4,5,6,7]\n",
        "\n",
        "# Define transforms on the dataset splits of CIFAR10. Here, we use random crops and horizontal flips for training augmentations.\n",
        "# Both the train and test sets are converted to PyTorch tensors and are normalized around the mean/std of CIFAR-10.\n",
        "cifar_training_transform = transforms.Compose([transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "cifar_test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "# To adapt to our setting, we must also fix the nature of the labels. Here, we remap ID labels to [0,1,2,...]\n",
        "# and OOD labels to len(id_classes).\n",
        "label_map = {id_classes[i]: i for i in range(len(id_classes))}\n",
        "cifar_label_transform = lambda x: label_map[x] if x in label_map else len(id_classes)\n",
        "\n",
        "# Get the dataset objects from PyTorch. Here, CIFAR10 is downloaded, and the transform is applied when points \n",
        "# are retrieved.\n",
        "cifar10_full_train = cifar.CIFAR10(download_path, train=True, download=True, transform=cifar_training_transform, target_transform=cifar_label_transform)\n",
        "cifar10_test = cifar.CIFAR10(download_path, train=False, download=True, transform=cifar_test_transform, target_transform=cifar_label_transform)\n",
        "\n",
        "# Get the dimension of the images. Here, we simply take the very first image of CIFAR10 \n",
        "# and query its dimension.\n",
        "dim = np.shape(cifar10_full_train[0][0])\n",
        "\n",
        "# We now define a train-unlabeled split for the sake of the experiment. Here, the initial train dataset\n",
        "# contains only in-distribution points\n",
        "num_train_examples_id_per_class = 200\n",
        "\n",
        "# The unlabeled dataset will be composed of both in-distribution points and OOD points.\n",
        "num_unlabeled_examples_id_per_class = 250\n",
        "num_unlabeled_examples_ood_per_class = 750\n",
        "\n",
        "# We assume that we have access to some OOD points initially. If we do not, then we can accrue them from the \n",
        "# unlabeled dataset iteratively after discovering them.\n",
        "num_held_out_ood_per_class = 10\n",
        "\n",
        "# Create the dataset splits using the above configuration\n",
        "train_idx = []\n",
        "unlabeled_idx = []\n",
        "test_idx = []\n",
        "held_out_ood_idx = []\n",
        "\n",
        "for class_idx in range(10):\n",
        "\n",
        "    # Retrieve all the indices of the elements in CIFAR-10 whose label matches class_idx\n",
        "    full_idx_class = torch.where(torch.Tensor(cifar10_full_train.targets) == class_idx)[0].cpu().numpy()\n",
        "\n",
        "    # Determine how many points to add for this class depending on the OOD flag of the class\n",
        "    if class_idx not in id_classes:\n",
        "        \n",
        "        # Choose indices for the unlabeled OOD points and the held-out OOD points for this class\n",
        "        class_unlabeled_idx = np.random.choice(full_idx_class, size=num_unlabeled_examples_ood_per_class, replace=False)\n",
        "        remaining_class_idx = np.array(list(set(full_idx_class) - set(class_unlabeled_idx)))\n",
        "        held_out_class_idx = np.random.choice(remaining_class_idx, size=num_held_out_ood_per_class, replace=False)\n",
        "\n",
        "        unlabeled_idx.extend(class_unlabeled_idx)\n",
        "        held_out_ood_idx.extend(held_out_class_idx)\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Choose indices for the labeled ID points and the unlabeled ID points for this class\n",
        "        class_train_idx = np.random.choice(full_idx_class, size=num_train_examples_id_per_class, replace=False)\n",
        "        remaining_class_idx = np.array(list(set(full_idx_class) - set(class_unlabeled_idx)))\n",
        "        class_unlabeled_idx = np.random.choice(remaining_class_idx, size=num_unlabeled_examples_id_per_class, replace=False)\n",
        "\n",
        "        train_idx.extend(class_train_idx)\n",
        "        unlabeled_idx.extend(class_unlabeled_idx)\n",
        "\n",
        "    # Lastly, we need to update the test dataset as well since we only want to evaluate on ID points.\n",
        "    if class_idx in id_classes:\n",
        "        test_idx_class = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "        test_idx.extend(test_idx_class)\n",
        "\n",
        "# Create the train and unlabeled subsets based on the index lists above. While the unlabeled set constructed here technically has labels, they \n",
        "# are only used when querying for labels. Hence, they only exist here for the sake of experimental design.\n",
        "cifar10_train = Subset(cifar10_full_train, train_idx)\n",
        "cifar10_unlabeled = Subset(cifar10_full_train, unlabeled_idx)\n",
        "cifar10_ood = Subset(cifar10_full_train, held_out_ood_idx)\n",
        "cifar10_test = Subset(cifar10_test, test_idx)"
      ],
      "id": "uaaAWcsKf6Uv",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjVjSm-slI7U"
      },
      "source": [
        "## Preparing the Model\n",
        "\n",
        "Here, we use DISTIL's provided implementation of the [ResNet-18](https://arxiv.org/abs/1512.03385) architecture. We also create a model directory to store trained models in this example."
      ],
      "id": "mjVjSm-slI7U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHfyJvslJID"
      },
      "source": [
        "# Use nclasses + 1. We care about the first 6 classes; the last one is not trained since we add no OOD training examples.\n",
        "# We use nclasses + 1 to avoid issues in the embedding computation used by SIMILAR.\n",
        "net = ResNet18(num_classes=nclasses + 1)  "
      ],
      "id": "LjHfyJvslJID",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fsSP89pl7Rk"
      },
      "source": [
        "# Initial Round"
      ],
      "id": "2fsSP89pl7Rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGAnKw8AoE_q"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have prepared the training data and the model, we can begin training an initial model. We use DISTIL's provided [training loop](https://github.com/decile-team/distil/blob/main/distil/utils/train_helper.py) to do training."
      ],
      "id": "eGAnKw8AoE_q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_PV51rl7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d68f6b7-1732-4cd7-989c-25841903c3b0"
      },
      "source": [
        "# Define the training arguments to use.\n",
        "args = {'n_epoch':      300,    # Stop training after 300 epochs.\n",
        "        'lr':           0.01,   # Use a learning rate of 0.01\n",
        "        'batch_size':   20,     # Update the parameters using training batches of size 20\n",
        "        'max_accuracy': 0.99,   # Stop training once the training accuracy has exceeded 0.99\n",
        "        'optimizer':    'sgd',  # Use the stochastic gradient descent optimizer\n",
        "        'device':       \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use a GPU if one is available\n",
        "        }\n",
        "\n",
        "# Create the training loop using our training dataset, provided model, and training arguments.\n",
        "# Train an initial model.\n",
        "dt = data_train(cifar10_train, net, args)\n",
        "trained_model = dt.train()"
      ],
      "id": "f6_PV51rl7f0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 120 Training accuracy: 0.991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY13YA4GoIvY"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "How does our initial model do on the test set?"
      ],
      "id": "yY13YA4GoIvY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGgL9oagoqKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4defc2b2-c38c-4c74-98eb-323e6d0312b2"
      },
      "source": [
        "# Get the full test accuracy\n",
        "full_test_accuracy = dt.get_acc_on_set(cifar10_test)\n",
        "print(F\"Full Test Accuracy: {full_test_accuracy}\")"
      ],
      "id": "uGgL9oagoqKT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Test Accuracy: 0.6238333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-47FnQRsfkM"
      },
      "source": [
        "The test performance could use improving. Can we add in-distribution points to help the learned model generalize better?"
      ],
      "id": "p-47FnQRsfkM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnDJvyMWtCCa"
      },
      "source": [
        "# Selecting In-Distribution Points"
      ],
      "id": "JnDJvyMWtCCa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH1qtKB4tK2v"
      },
      "source": [
        "## Preparing a Query Set and a Conditioning Set\n",
        "\n",
        "In this example, we know that there are OOD examples in the unlabeled dataset that can help us improve the accuracy of the model. How do we avoid selecting these points if we do not know *where* they are in the unlabeled dataset? Here, we use [SIMILAR](https://arxiv.org/abs/2107.00717) to select in-distribution examples from the unlabeled set. SIMILAR requires access to a query set of points that it uses to choose unlabeled points that are similar to it. It also requires access to a conditioning (private) set of points that it uses to choose unlabeled points that are dissimilar to it. In this fashion, we can formulate a query set of in-distribution points and a conditioning set of OOD points to effectively choose in-distribution points.\n",
        "\n",
        "Where do we get the query set? Luckily, we already have a couple points in our training dataset to choose. We will use the held-out OOD points for our conditioning set."
      ],
      "id": "lH1qtKB4tK2v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQupSdbrur3_"
      },
      "source": [
        "# Create a query set that contains the in-distribution examples of the training dataset\n",
        "query_set = cifar10_train\n",
        "\n",
        "# Use the held-out points for the private set\n",
        "private_set = cifar10_ood"
      ],
      "id": "MQupSdbrur3_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgvh20tYviAr"
      },
      "source": [
        "## Using DISTIL's SIMILAR Implementation: SCMI\n",
        "\n",
        "Now that we have the query and private sets, we are ready to use DISTIL's implementation of SIMILAR. In particular, we use the submodular conditional mutual information [strategy](https://github.com/decile-team/distil/blob/main/distil/active_learning_strategies/smi.py) that is detailed in [SIMILAR](https://arxiv.org/abs/2107.00717). This will allow us to select a set of points to label within a specified budget $k$.\n",
        "\n",
        "Specifically, the strategy attempts to maximize the [submodular conditional mutual information](https://arxiv.org/abs/2006.15412) between a subset $\\mathcal{A}$ of size no greater than $k$ of the unlabeled dataset $\\mathcal{U}$ and the query set $\\mathcal{Q}$ given the conditioning set $\\mathcal{P}$:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{argmax}_{\\mathcal{A} \\subseteq \\mathcal{U}, |\\mathcal{A}|\\leq k} I_F(\\mathcal{A};\\mathcal{Q}|\\mathcal{P})\n",
        "\\end{align}\n",
        "\n",
        "where $F$ is a submodular set function."
      ],
      "id": "cgvh20tYviAr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPKl0J3HyZZO"
      },
      "source": [
        "# Define arguments for SCMI\n",
        "selection_strategy_args = {'device':        args['device'],       # Use the device used in training\n",
        "                           'batch_size':    args['batch_size'],   # Use the batch size used in training\n",
        "                           'scmi_function':  'flcmi',              # Use a facility location function, which captures representation information\n",
        "                           'metric':        'cosine',             # Use cosine similarity when determining the likeness of two data points\n",
        "                           'optimizer':     'LazyGreedy'          # When doing submodular maximization, use the lazy greedy optimizer\n",
        "                          }\n",
        "\n",
        "# Create the SCMI selection strategy. Note: We remove the labels from the unlabeled portion of CIFAR-10 that we created earlier.\n",
        "# In a practical application, one would not have these labels a priori. Note: Since the OOD private set has class len(id_classes), we need to add 1 to nclasses.\n",
        "selection_strategy = SCMI(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), query_set, private_set, trained_model, nclasses + 1, selection_strategy_args)\n",
        "\n",
        "# Disable the augmentations used in the training dataset. Since all augmentations come from the cifar10_full_train object, we set its transform to the \n",
        "# transform used by the test set.\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "\n",
        "# Do the selection, which will return the indices of the selected points with respect to the unlabeled dataset.\n",
        "budget = 400\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "\n",
        "# Re-enable augmentations\n",
        "cifar10_full_train.transform = cifar_training_transform"
      ],
      "id": "HPKl0J3HyZZO",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQAIxhA1dLE"
      },
      "source": [
        "## Labeling the Points\n",
        "\n",
        "Now that we know which points should be labeled, we can present them to human labelers for annotation. Here, we can do so automatically since we already know their labels for the sake of the example."
      ],
      "id": "zoQAIxhA1dLE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlQ5Fr51yS8"
      },
      "source": [
        "# Form a labeled subset of the unlabeled dataset. Again, we already have the labels, \n",
        "# so we simply take a subset. Note, however, that the selection was done without the \n",
        "# use of the labels and that we would normally not have these labels. Hence, the \n",
        "# following statement would usually require human effort to complete.\n",
        "scmi_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)"
      ],
      "id": "HAlQ5Fr51yS8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zom1rZrJ2Wi_"
      },
      "source": [
        "## Characterizing the Selection\n",
        "\n",
        "Now that we have selected and labeled these new points, we can add them to the training dataset and retrain our model. Before that, how many points did we select that actually were in-distribution points?"
      ],
      "id": "Zom1rZrJ2Wi_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN22GOF-2W1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fb9973-8ca4-41fb-bf41-9e0b29d6ce5b"
      },
      "source": [
        "# Go over the newly labeled dataset, tallying the number of points seen in each class.\n",
        "in_distribution_points = 0\n",
        "for _, label in scmi_human_labeled_dataset:\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_points += 1\n",
        "\n",
        "# Print total ID count\n",
        "print(F\"Total In-Distribution Points: {in_distribution_points}\")\n",
        "print(F\"Fraction of Budget: {in_distribution_points / budget}\")"
      ],
      "id": "GN22GOF-2W1M",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total In-Distribution Points: 208\n",
            "Fraction of Budget: 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZx_yx07sEw"
      },
      "source": [
        "We were able to get a good number of in-distribution points. For comparison sake, how many in-distribution points would we get using some of DISTIL's other strategies?"
      ],
      "id": "xyZx_yx07sEw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvDNvY3D9hSn"
      },
      "source": [
        "**BADGE**"
      ],
      "id": "FvDNvY3D9hSn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_iPljF9e_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a73b285-7872-48f5-d94e-8855e077d741"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = BADGE(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses + 1, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 400\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "badge_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "in_distribution_points = 0\n",
        "for _, label in badge_human_labeled_dataset:\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_points += 1\n",
        "\n",
        "# Print total ID count\n",
        "print(F\"Total In-Distribution Points: {in_distribution_points}\")\n",
        "print(F\"Fraction of Budget: {in_distribution_points / budget}\")"
      ],
      "id": "HN_iPljF9e_L",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total In-Distribution Points: 103\n",
            "Fraction of Budget: 0.2575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1PDZ2qk-hi7"
      },
      "source": [
        "**Random**"
      ],
      "id": "E1PDZ2qk-hi7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4DQ3_ld-j8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac283dc2-51c5-4c77-e644-8a4dbd0d0951"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = RandomSampling(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses + 1, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 400\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "random_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "in_distribution_points = 0\n",
        "for _, label in random_human_labeled_dataset:\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_points += 1\n",
        "\n",
        "# Print total ID count\n",
        "print(F\"Total In-Distribution Points: {in_distribution_points}\")\n",
        "print(F\"Fraction of Budget: {in_distribution_points / budget}\")"
      ],
      "id": "o4DQ3_ld-j8U",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total In-Distribution Points: 145\n",
            "Fraction of Budget: 0.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5KB_UH-zR2"
      },
      "source": [
        "**Entropy**"
      ],
      "id": "wK5KB_UH-zR2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncA_-JMA-zoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a7cf29-2396-408a-f984-b0637cfa7bdf"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = EntropySampling(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses + 1, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 400\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "entropy_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "in_distribution_points = 0\n",
        "for _, label in entropy_human_labeled_dataset:\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_points += 1\n",
        "\n",
        "# Print total ID count\n",
        "print(F\"Total In-Distribution Points: {in_distribution_points}\")\n",
        "print(F\"Fraction of Budget: {in_distribution_points / budget}\")"
      ],
      "id": "ncA_-JMA-zoA",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total In-Distribution Points: 80\n",
            "Fraction of Budget: 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvMg93--Byvl"
      },
      "source": [
        "Hence, we can see that SCMI does comparatively better at selecting in-distribution instances."
      ],
      "id": "RvMg93--Byvl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjvhIDHsAkU1"
      },
      "source": [
        "# Improving Performance"
      ],
      "id": "vjvhIDHsAkU1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF-HsA27AsUG"
      },
      "source": [
        "## Re-Training\n",
        "\n",
        "Let us re-train our model using the newly selected points. Note, however, that we only want to add the in-distribution points."
      ],
      "id": "eF-HsA27AsUG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kkbzgxVAkl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ba54f1-e1fb-4376-d185-17fe6562e193"
      },
      "source": [
        "# Create a new training dataset by concatenating what we have with the newly labeled in-distribution points.\n",
        "in_distribution_selected_idx = []\n",
        "for index, (_, label) in enumerate(scmi_human_labeled_dataset):\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_selected_idx.append(index)\n",
        "in_distribution_scmi_human_labeled_dataset = Subset(scmi_human_labeled_dataset, in_distribution_selected_idx)\n",
        "\n",
        "new_training_dataset = ConcatDataset([cifar10_train, in_distribution_scmi_human_labeled_dataset])\n",
        "print(\"New Training Dataset Length:\", len(new_training_dataset))\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()"
      ],
      "id": "1kkbzgxVAkl7",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training Dataset Length: 1408\n",
            "Training..\n",
            "Epoch: 123 Training accuracy: 0.991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtUxT2pBLx_"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Now, let us see the accuracy improvement."
      ],
      "id": "6PtUxT2pBLx_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xj8wmgPBP9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc4e12a-ad25-48d9-d893-443acf0fd934"
      },
      "source": [
        "# Get the full test accuracy\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")"
      ],
      "id": "2Xj8wmgPBP9U",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Test Accuracy Improvement: 0.6238333333333334 to 0.6513333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK89JhX6Fq3s"
      },
      "source": [
        "## Comparison\n",
        "\n",
        "What would the accuracy improvement look like if we had used the other methods?"
      ],
      "id": "BK89JhX6Fq3s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxklRX4uF1UO"
      },
      "source": [
        "**BADGE**"
      ],
      "id": "jxklRX4uF1UO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0_1FoFYF8pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb590709-2b4e-4d81-bd03-fc49a29975e5"
      },
      "source": [
        "# Repeat the process\n",
        "in_distribution_selected_idx = []\n",
        "for index, (_, label) in enumerate(badge_human_labeled_dataset):\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_selected_idx.append(index)\n",
        "in_distribution_badge_human_labeled_dataset = Subset(badge_human_labeled_dataset, in_distribution_selected_idx)\n",
        "\n",
        "new_training_dataset = ConcatDataset([cifar10_train, in_distribution_badge_human_labeled_dataset])\n",
        "print(\"New Training Dataset Length:\", len(new_training_dataset))\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")"
      ],
      "id": "X0_1FoFYF8pU",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training Dataset Length: 1303\n",
            "Training..\n",
            "Epoch: 145 Training accuracy: 0.992\n",
            "Full Test Accuracy Improvement: 0.6238333333333334 to 0.6311666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNArqgcGF41l"
      },
      "source": [
        "**Random**"
      ],
      "id": "gNArqgcGF41l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgD2s2lF86O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9948923-ae1f-438c-b488-c7d4ae9057cc"
      },
      "source": [
        "# Repeat the process\n",
        "in_distribution_selected_idx = []\n",
        "for index, (_, label) in enumerate(random_human_labeled_dataset):\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_selected_idx.append(index)\n",
        "in_distribution_random_human_labeled_dataset = Subset(random_human_labeled_dataset, in_distribution_selected_idx)\n",
        "\n",
        "new_training_dataset = ConcatDataset([cifar10_train, in_distribution_random_human_labeled_dataset])\n",
        "print(\"New Training Dataset Length:\", len(new_training_dataset))\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")"
      ],
      "id": "xUgD2s2lF86O",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training Dataset Length: 1345\n",
            "Training..\n",
            "Epoch: 130 Training accuracy: 0.99\n",
            "Full Test Accuracy Improvement: 0.6238333333333334 to 0.6201666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcyKstqF5Ml"
      },
      "source": [
        "**Entropy**"
      ],
      "id": "SkcyKstqF5Ml"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlB34d8fF9bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fd2424-ff82-4597-bbe5-caebd258646e"
      },
      "source": [
        "# Repeat the process\n",
        "in_distribution_selected_idx = []\n",
        "for index, (_, label) in enumerate(entropy_human_labeled_dataset):\n",
        "    if label != len(id_classes):\n",
        "        in_distribution_selected_idx.append(index)\n",
        "in_distribution_entropy_human_labeled_dataset = Subset(entropy_human_labeled_dataset, in_distribution_selected_idx)\n",
        "\n",
        "new_training_dataset = ConcatDataset([cifar10_train, in_distribution_entropy_human_labeled_dataset])\n",
        "print(\"New Training Dataset Length:\", len(new_training_dataset))\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")"
      ],
      "id": "nlB34d8fF9bP",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training Dataset Length: 1280\n",
            "Training..\n",
            "Epoch: 131 Training accuracy: 0.993\n",
            "Full Test Accuracy Improvement: 0.6238333333333334 to 0.6231666666666666\n"
          ]
        }
      ]
    }
  ]
}