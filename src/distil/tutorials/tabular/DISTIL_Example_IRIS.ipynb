{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRIS Example.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGGJTKLK0SU"
      },
      "source": [
        "# **DISTIL Usage Example: Iris**\n",
        "\n",
        "Here, we show how to use DISTIL to perform active learning on tabular data (Iris). This notebook can be easily executed on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW2wJKUoL1I-"
      },
      "source": [
        "## Installations and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iiAc1qWL5Db"
      },
      "source": [
        "# Get DISTIL\n",
        "!git clone https://github.com/decile-team/distil.git\n",
        "!pip install -r distil/requirements/requirements.txt\n",
        "\n",
        "# Get Iris dataset, which is kept in our datasets repository\n",
        "!git clone https://github.com/decile-team/datasets.git\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "sys.path.append('distil/')\n",
        "from distil.utils.utils import LabeledToUnlabeledDataset                        # Converts a PyTorch dataset with labels to one without labels\n",
        "from distil.active_learning_strategies.core_set import CoreSet                   # Our choice of active learning strategy for this example\n",
        "from distil.utils.models.simple_net import TwoLayerNet                          # Our choice of model for this example\n",
        "from distil.utils.train_helper import data_train                                # The training loop used in between AL selections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opnHILkQPta8"
      },
      "source": [
        "## Preparing Iris\n",
        "\n",
        "The data for Iris is prepared in this step. Here, we load the data, normalize it, partition the train dataset into a labeled seed set and unlabeled set, and formulate PyTorch datasets. The main output of this step is to create the PyTorch dataset objects used in training and by DISTIL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qwO5cWhJ4Ie"
      },
      "source": [
        "data_path = 'datasets/iris.csv'\n",
        "test_path = 'datasets/iris_test.csv'\n",
        "\n",
        "# Iris is a very simple dataset. There are only 3 classes with 50 examples each.\n",
        "nclasses = 3    \n",
        "\n",
        "# Use pandas to load the train csv. Use pandas dataframe to get input features and corresponding labels\n",
        "df = pd.read_csv(data_path)\n",
        "X = df.iloc[:,:-1].to_numpy()\n",
        "y = df.iloc[:, -1].to_numpy()\n",
        "\n",
        "# Here, we define our initial labeled seed set. We simply take the first 10 points.\n",
        "X_tr = X[:10]    \n",
        "y_tr = y[:10]\n",
        "\n",
        "# Here, we define the unlabeled set as the remainder of the original train set.\n",
        "X_unlabeled = X[10:]\n",
        "y_unlabeled = y[10:]\t\t\n",
        "\n",
        "# As before, load the test csv.\n",
        "df_test = pd.read_csv(test_path)\n",
        "X_test = df_test.iloc[:,:-1].to_numpy()\n",
        "y_test = df_test.iloc[:, -1].to_numpy()\n",
        "\n",
        "# Record the number of samples and the dimensionality of the samples\n",
        "nSamps, dim = np.shape(X)\n",
        "\n",
        "# Lastly, we create the PyTorch dataset objects. Here, the unlabeled dataset technically has labels;\n",
        "# however, we will explicitly remove these labels when it is used by DISTIL's active learning strategy.\n",
        "# It only contains the labels in this notebook for the sake of experimental design.\n",
        "training_dataset = TensorDataset(torch.tensor(X_tr, dtype=torch.float), torch.tensor(y_tr, dtype=torch.long))\n",
        "unlabeled_dataset = TensorDataset(torch.tensor(X_unlabeled, dtype=torch.float), torch.tensor(y_unlabeled, dtype=torch.long))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.long))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCO6jUYoQ1-S"
      },
      "source": [
        "## Preparing the Model\n",
        "\n",
        "Here, we use DISTIL's two-layer network, which consists of a hidden layer of ReLU activations. We specify the input dimension via the first argument, the number of output classes via the second argument, and the number of hidden units via the third argument. The network then has its weights initialized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkiY_qXzQ2SO"
      },
      "source": [
        "def init_weights(m):\n",
        "    \"\"\"\n",
        "    Used to initialize network weights\n",
        "    \"\"\"\n",
        "\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "net = TwoLayerNet(dim, nclasses, dim*2)\n",
        "net.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE5uH8TQSMYG"
      },
      "source": [
        "## Defining the Active Learning Strategy\n",
        "\n",
        "We now have all that we need to create the active learning strategy object. For this example, we use [CoreSet](https://arxiv.org/abs/1708.00489). The CoreSet strategy takes the current labeled dataset (training_dataset), the current unlabeled dataset (unlabeled_dataset, which has its labels stripped via the LabeledToUnlabeledDataset wrapper), the model (net), the number of classes (num_cls), and various strategy arguments (strategy_args)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ON0t61SMqc"
      },
      "source": [
        "# We specify a specific batch size that should be used when loading/handling data \n",
        "# within the strategy.\n",
        "strategy_args = {'batch_size' : 10}\n",
        "strategy = CoreSet(training_dataset, LabeledToUnlabeledDataset(unlabeled_dataset), net, nclasses, strategy_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLRHPlivTXFH"
      },
      "source": [
        "## Perform the AL Loop\n",
        "\n",
        "We can now begin the active learning loop. Here, we define our training loop through DISTIL's utility training loop. We continuously select points using margin sampling, label them, add them to the train dataset, retrain the model, and repeat for a certain number of rounds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ0IJ9g9TXeT"
      },
      "source": [
        "# Define the training loop arguments. Here, we specify that training should stop after \n",
        "# 150 epochs. Internally, the training class also stops at 0.95 training accuracy. This \n",
        "# can be changed by specifying a max_accuracy parameter here.\n",
        "train_args = {'n_epoch':150, 'lr':float(0.001), 'batch_size': 5, 'optimizer':'sgd'}\n",
        "n_rounds = 11     # Number of AL rounds to perform\n",
        "budget = 4        # Size of subset to label during each AL selection\n",
        "\n",
        "# Keep track of the test accuracy obtained at each round to measure progress\n",
        "acc = np.zeros(n_rounds)\n",
        "\n",
        "# Create the training loop class.\n",
        "dt = data_train(training_dataset, net, train_args)\n",
        "\n",
        "# Do one round of training. To make accurate selections, the model must at least be trained on the seed set data.\n",
        "clf = dt.train()\n",
        "\n",
        "# Update the active learning strategy's stored model.\n",
        "strategy.update_model(clf)\n",
        "\n",
        "# Use the active learning strategy's predict() method to obtain model predictions on the test features.\n",
        "# Obtain initial test accuracy using predictions.\n",
        "y_pred = strategy.predict(LabeledToUnlabeledDataset(test_dataset)).cpu().numpy()\n",
        "acc[0] = (1.0*(y_test == y_pred)).sum().item() / len(y_test)\n",
        "print('Initial Testing accuracy:', round(acc[0], 3), flush=True)\n",
        "\n",
        "# User-Controlled Loop\n",
        "for rd in range(1, n_rounds):\n",
        "    print('-------------------------------------------------')\n",
        "    print('Round', rd) \n",
        "    print('-------------------------------------------------')\n",
        "\n",
        "    # The main functionality of the active learning class: the select() function.\n",
        "    # It retrieves the indices of points in the unlabeled set that should be labeled \n",
        "    # and added to the training set.\n",
        "    idx = strategy.select(budget)\n",
        "    print('New data points added -', len(idx))\n",
        "\n",
        "    # Add the new points to the training set. Here, we do so by modifying the underlying\n",
        "    # numpy arrays. Here, the selected features are concatenated to the training set \n",
        "    # features.\n",
        "    X_tr = np.concatenate((X_tr, X_unlabeled[idx]), axis=0)\n",
        "    X_unlabeled = np.delete(X_unlabeled, idx, axis = 0)\n",
        "\n",
        "    # Here, we concatenate the labels of the selected point to the labels of teh training set.\n",
        "    # This step is done by the human in actual applications; here, it is done automatically \n",
        "    # via our a priori knowledge.\n",
        "    y_tr = np.concatenate((y_tr, y_unlabeled[idx]), axis = 0)\n",
        "    y_unlabeled = np.delete(y_unlabeled, idx, axis = 0)\n",
        "    print('Number of training points -',X_tr.shape[0])\n",
        "    print('Number of labels -', y_tr.shape[0])\n",
        "    print('Number of unlabeled points -', X_unlabeled.shape[0])\n",
        "\n",
        "    # Update the PyTorch dataset objects.\n",
        "    training_dataset = TensorDataset(torch.tensor(X_tr, dtype=torch.float), torch.tensor(y_tr, dtype=torch.long))\n",
        "    unlabeled_dataset = TensorDataset(torch.tensor(X_unlabeled, dtype=torch.float), torch.tensor(y_unlabeled, dtype=torch.long))\n",
        "\n",
        "    # Update the data used in the active learning strategy and the training loop\n",
        "    strategy.update_data(training_dataset, LabeledToUnlabeledDataset(unlabeled_dataset))\n",
        "    dt.update_data(training_dataset)\n",
        "\n",
        "    # Retrain the model using the new labeled data. Update the active learning strategy using \n",
        "    # the newly trained model.\n",
        "    clf = dt.train()\n",
        "    strategy.update_model(clf)\n",
        "\n",
        "    # Get the test accuracy as before.\n",
        "    y_pred = strategy.predict(LabeledToUnlabeledDataset(test_dataset)).cpu().numpy()\n",
        "    acc[rd] = round(1.0 * (y_test == y_pred).sum().item() / len(y_test), 3)\n",
        "    print('Testing accuracy:', acc[rd], flush=True)\n",
        "\n",
        "    # We add an additional condition here to stop once test accuracy exceeds 0.98. Ideally,\n",
        "    # you'd want to stop at a target test accuracy, anyways.\n",
        "    if acc[rd] > 0.98:\n",
        "        print('Testing accuracy reached above 98%, stopping training!')\n",
        "        break\n",
        "        \n",
        "print('Training Completed')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}