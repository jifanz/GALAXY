{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DISTIL_Example_Rare_Classes_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6c124d0a4f44af49b75538f5ae5a65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6512a31879f74f52994053855cad20f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13a57e1649c2493abc9c2316346c2c00",
              "IPY_MODEL_7218a876ac604496b0ce80e102bc41d4",
              "IPY_MODEL_d51133930b1846d5936164ba074cf314"
            ]
          }
        },
        "6512a31879f74f52994053855cad20f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13a57e1649c2493abc9c2316346c2c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f84c1ab103ce4d22851fdc5f97492534",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01bf17b1d0664c458000e247bff226cc"
          }
        },
        "7218a876ac604496b0ce80e102bc41d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08aac64f9fda4b9c947dd5ba16851a75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd8af92f3ea24d11ae99326355b0dbad"
          }
        },
        "d51133930b1846d5936164ba074cf314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df2cb908e3a348f8ade155723ad4a340",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 54326632.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc181c05735a42c28ca5783f351940c7"
          }
        },
        "f84c1ab103ce4d22851fdc5f97492534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01bf17b1d0664c458000e247bff226cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08aac64f9fda4b9c947dd5ba16851a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd8af92f3ea24d11ae99326355b0dbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df2cb908e3a348f8ade155723ad4a340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc181c05735a42c28ca5783f351940c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOkAr6RnQ2BJ"
      },
      "source": [
        "# DISTIL Usage Example: CIFAR-10 with Rare Classes\n",
        "\n",
        "Not all datasets have an even spread of classes among the set of labels. Indeed, a dataset might have only a couple elements that have a particular class as a label. Such classes are considered *rare*, and extra work is required to achieve good model performance on these examples. The typical fix is to provide more data with the rare-class label; however, this issue is complicated by the fact that this data is usually part of a massive unlabeled pool of data. Here, we show how to use DISTIL's implementation of [SIMILAR](https://arxiv.org/abs/2107.00717) to mine these rare examples for labeling."
      ],
      "id": "lOkAr6RnQ2BJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ibaupa-l2T_"
      },
      "source": [
        "# Preparation"
      ],
      "id": "-Ibaupa-l2T_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViAJ7rawfp53"
      },
      "source": [
        "## Installation and Imports"
      ],
      "id": "ViAJ7rawfp53"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmhefeJQfqKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3839b887-5dad-4e50-b9f7-2c18d05c0391"
      },
      "source": [
        "# Get DISTIL\n",
        "!git clone https://github.com/decile-team/distil.git\n",
        "!pip install -r distil/requirements/requirements.txt\n",
        "\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, Subset, ConcatDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import cifar\n",
        "\n",
        "sys.path.append('distil/')\n",
        "from distil.active_learning_strategies import SMI, GLISTER, BADGE, EntropySampling, RandomSampling  # All active learning strategies showcased in this example\n",
        "from distil.utils.models.resnet import ResNet18                                                     # The model used in our image classification example\n",
        "from distil.utils.train_helper import data_train                                                    # A utility training class provided by DISTIL\n",
        "from distil.utils.utils import LabeledToUnlabeledDataset                                            # A utility wrapper class that removes labels from labeled PyTorch dataset objects"
      ],
      "id": "nmhefeJQfqKb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'distil'...\n",
            "remote: Enumerating objects: 3324, done.\u001b[K\n",
            "remote: Counting objects: 100% (1281/1281), done.\u001b[K\n",
            "remote: Compressing objects: 100% (812/812), done.\u001b[K\n",
            "remote: Total 3324 (delta 794), reused 841 (delta 461), pack-reused 2043\u001b[K\n",
            "Receiving objects: 100% (3324/3324), 23.05 MiB | 21.87 MiB/s, done.\n",
            "Resolving deltas: 100% (2067/2067), done.\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
            "Collecting sphinxcontrib-bibtex>=2.3.0\n",
            "  Downloading sphinxcontrib_bibtex-2.4.1-py3-none-any.whl (38 kB)\n",
            "Collecting multipledispatch==0.6.0\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting scikit-learn==0.23.0\n",
            "  Downloading scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 6)) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 8)) (0.51.2)\n",
            "Collecting submodlib\n",
            "  Downloading https://test-files.pythonhosted.org/packages/55/62/88e02a0e170498f38f7b9ce22b3e0a6a3cf9c82a33d3553da693c5c52872/submodlib-1.1.5.tar.gz (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 12)) (1.1.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r distil/requirements/requirements.txt (line 13)) (0.11.1+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch==0.6.0->-r distil/requirements/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->-r distil/requirements/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->-r distil/requirements/requirements.txt (line 3)) (3.0.0)\n",
            "Collecting Sphinx>=2.1\n",
            "  Downloading Sphinx-4.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 55.1 MB/s \n",
            "\u001b[?25hCollecting pybtex-docutils>=1.0.0\n",
            "  Downloading pybtex_docutils-1.0.1-py3-none-any.whl (4.8 kB)\n",
            "Requirement already satisfied: docutils>=0.8 in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (0.17.1)\n",
            "Collecting pybtex>=0.20\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[K     |████████████████████████████████| 561 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r distil/requirements/requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->-r distil/requirements/requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->-r distil/requirements/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.7/dist-packages (from pybtex>=0.20->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.13)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 12.9 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.1.5)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.11.3)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (21.3)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (0.7.12)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from submodlib->-r distil/requirements/requirements.txt (line 11)) (0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r distil/requirements/requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r distil/requirements/requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->Sphinx>=2.1->sphinxcontrib-bibtex>=2.3.0->-r distil/requirements/requirements.txt (line 1)) (3.0.6)\n",
            "Building wheels for collected packages: submodlib\n",
            "  Building wheel for submodlib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for submodlib: filename=submodlib-1.1.5-cp37-cp37m-linux_x86_64.whl size=512655 sha256=5f42dc2a440923593a5ac15c93121875e37f2103e924b5f2e7d3836a671a3b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/3c/03/48ce7dd03798c0564b61e61020e733443aed88e115518442b4\n",
            "Successfully built submodlib\n",
            "Installing collected packages: latexcodec, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, scikit-learn, pybtex, Sphinx, pybtex-docutils, submodlib, sphinxcontrib-bibtex, multipledispatch\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: Sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Sphinx-4.3.1 latexcodec-2.0.1 multipledispatch-0.6.0 pybtex-0.24.0 pybtex-docutils-1.0.1 scikit-learn-0.23.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.4.1 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 submodlib-1.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4oIq8U7f6Dw"
      },
      "source": [
        "## Preparing CIFAR-10 with Rare Classes\n",
        "\n",
        "The CIFAR10 dataset contains 60,000 32x32 color images in 10 different classes.The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. The training set contains 50,000 images, and the test set contains 10,000 images. Here, we do a simple setup of the CIFAR10 dataset that we will use in this example. More importantly, we define a split on CIFAR10's training set into an initial labeled seed set and an unlabeled set. We also impose an artificial imbalance among the classes to simulate a rare-class scenario."
      ],
      "id": "v4oIq8U7f6Dw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaaAWcsKf6Uv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "e6c124d0a4f44af49b75538f5ae5a65d",
            "6512a31879f74f52994053855cad20f1",
            "13a57e1649c2493abc9c2316346c2c00",
            "7218a876ac604496b0ce80e102bc41d4",
            "d51133930b1846d5936164ba074cf314",
            "f84c1ab103ce4d22851fdc5f97492534",
            "01bf17b1d0664c458000e247bff226cc",
            "08aac64f9fda4b9c947dd5ba16851a75",
            "dd8af92f3ea24d11ae99326355b0dbad",
            "df2cb908e3a348f8ade155723ad4a340",
            "cc181c05735a42c28ca5783f351940c7"
          ]
        },
        "outputId": "7c1a86af-cf02-4ee6-8698-c4ec4f2a8e30"
      },
      "source": [
        "# Define the name of the dataset and the path that PyTorch should use when downloading the data\n",
        "data_set_name = 'CIFAR10'\n",
        "download_path = '.'\n",
        "\n",
        "# Define the number of classes in CIFAR10\n",
        "nclasses = 10\n",
        "\n",
        "# Define transforms on the dataset splits of CIFAR10. Here, we use random crops and horizontal flips for training augmentations.\n",
        "# Both the train and test sets are converted to PyTorch tensors and are normalized around the mean/std of CIFAR-10.\n",
        "cifar_training_transform = transforms.Compose([transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "cifar_test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "# Get the dataset objects from PyTorch. Here, CIFAR10 is downloaded, and the transform is applied when points \n",
        "# are retrieved.\n",
        "cifar10_full_train = cifar.CIFAR10(download_path, train=True, download=True, transform=cifar_training_transform)\n",
        "cifar10_test = cifar.CIFAR10(download_path, train=False, download=True, transform=cifar_test_transform)\n",
        "\n",
        "# Get the dimension of the images. Here, we simply take the very first image of CIFAR10 \n",
        "# and query its dimension.\n",
        "dim = np.shape(cifar10_full_train[0][0])\n",
        "\n",
        "# We now define a train-unlabeled split for the sake of the experiment. Here, we specify the ratio of common classes to rare classes\n",
        "# for both the initial training seed set and the unlabeled set. We use a ratio of 10:1.\n",
        "num_examples_per_common_class_seed = 400\n",
        "num_examples_per_rare_class_seed = 40\n",
        "\n",
        "num_examples_per_common_class_unlabeled = 3000\n",
        "num_examples_per_rare_class_unlabeled = 300\n",
        "\n",
        "# We create the imbalance on classes 5,6,7,8,9.\n",
        "rare_classes = [5,6,7,8,9]\n",
        "\n",
        "# Create the imbalance by choosing which indices of the full training set to assign to the initial labeled seed set and the unlabeled set\n",
        "train_idx = []\n",
        "unlabeled_idx = []\n",
        "\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    # Retrieve all the indices of the elements in CIFAR-10 whose label matches class_idx\n",
        "    full_idx_class = torch.where(torch.Tensor(cifar10_full_train.targets) == class_idx)[0].cpu().numpy()\n",
        "\n",
        "    # Determine how many points to add for this class depending on the rarity of the class\n",
        "    if class_idx in rare_classes:\n",
        "        class_num_training_examples_to_add = num_examples_per_rare_class_seed\n",
        "        class_num_unlabeled_examples_to_add = num_examples_per_rare_class_unlabeled\n",
        "    else:\n",
        "        class_num_training_examples_to_add = num_examples_per_common_class_seed\n",
        "        class_num_unlabeled_examples_to_add = num_examples_per_common_class_unlabeled\n",
        "\n",
        "    # Choose randomly a subset of these indices. These will be added to the initial training seed set.\n",
        "    class_train_idx = np.random.choice(full_idx_class, size=class_num_training_examples_to_add, replace=False)\n",
        "\n",
        "    # Choose randomly a subset of the remaining indices. These will be added to the unlabeled set.\n",
        "    remaining_class_idx = np.array(list(set(full_idx_class) - set(class_train_idx)))\n",
        "    class_unlabeled_idx = np.random.choice(remaining_class_idx, size=class_num_unlabeled_examples_to_add, replace=False)\n",
        "\n",
        "    # Add the chosen indices to the growing subset lists\n",
        "    train_idx.extend(class_train_idx)\n",
        "    unlabeled_idx.extend(class_unlabeled_idx)\n",
        "\n",
        "# Create the train and unlabeled subsets based on the index lists above. While the unlabeled set constructed here technically has labels, they \n",
        "# are only used when querying for labels. Hence, they only exist here for the sake of experimental design.\n",
        "cifar10_train = Subset(cifar10_full_train, train_idx)\n",
        "cifar10_unlabeled = Subset(cifar10_full_train, unlabeled_idx)"
      ],
      "id": "uaaAWcsKf6Uv",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6c124d0a4f44af49b75538f5ae5a65d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjVjSm-slI7U"
      },
      "source": [
        "## Preparing the Model\n",
        "\n",
        "Here, we use DISTIL's provided implementation of the [ResNet-18](https://arxiv.org/abs/1512.03385) architecture. We also create a model directory to store trained models in this example."
      ],
      "id": "mjVjSm-slI7U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHfyJvslJID"
      },
      "source": [
        "net = ResNet18()"
      ],
      "id": "LjHfyJvslJID",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fsSP89pl7Rk"
      },
      "source": [
        "# Initial Round"
      ],
      "id": "2fsSP89pl7Rk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGAnKw8AoE_q"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have prepared the training data and the model, we can begin training an initial model. We use DISTIL's provided [training loop](https://github.com/decile-team/distil/blob/main/distil/utils/train_helper.py) to do training."
      ],
      "id": "eGAnKw8AoE_q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_PV51rl7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d486a07-15cd-490d-a921-0d60626a10d9"
      },
      "source": [
        "# Define the training arguments to use.\n",
        "args = {'n_epoch':      300,    # Stop training after 300 epochs.\n",
        "        'lr':           0.01,   # Use a learning rate of 0.01\n",
        "        'batch_size':   20,     # Update the parameters using training batches of size 20\n",
        "        'max_accuracy': 0.99,   # Stop training once the training accuracy has exceeded 0.99\n",
        "        'optimizer':    'sgd',  # Use the stochastic gradient descent optimizer\n",
        "        'device':       \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use a GPU if one is available\n",
        "        }\n",
        "\n",
        "# Create the training loop using our training dataset, provided model, and training arguments.\n",
        "# Train an initial model.\n",
        "dt = data_train(cifar10_train, net, args)\n",
        "trained_model = dt.train()"
      ],
      "id": "f6_PV51rl7f0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 105 Training accuracy: 0.991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY13YA4GoIvY"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "How does our initial model do on the test set? Furthermore, how does our initial model do on the *rare classes* of the test set? Luckily, the training loop provided by DISTIL also provides a way to measure the accuracy of the model on a given dataset. We measure both accuracies here."
      ],
      "id": "yY13YA4GoIvY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGgL9oagoqKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1c361c-e29a-4a1c-83a9-ee0f26028363"
      },
      "source": [
        "# Get the full test accuracy\n",
        "full_test_accuracy = dt.get_acc_on_set(cifar10_test)\n",
        "print(F\"Full Test Accuracy: {full_test_accuracy}\")\n",
        "\n",
        "# Get the per-class test accuracies\n",
        "rare_indices = []\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    # Get the indices of the test set corresponding to this class\n",
        "    test_rare_class_subset_idx = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "    \n",
        "    if class_idx in rare_classes:\n",
        "        rare_indices.extend(test_rare_class_subset_idx)\n",
        "\n",
        "    # Get the accuracy on this class subset\n",
        "    cifar10_test_class_subset = Subset(cifar10_test, test_rare_class_subset_idx)\n",
        "    rare_class_test_accuracy = dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    print(F\"Class {class_idx} Test Accuracy: {rare_class_test_accuracy}\")\n",
        "\n",
        "# Get accuracy on all rare points\n",
        "cifar10_test_rare_subset = Subset(cifar10_test, rare_indices)\n",
        "rare_test_accuracy = dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "print(F\"Rare Test Accuracy: {rare_test_accuracy}\")"
      ],
      "id": "uGgL9oagoqKT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Test Accuracy: 0.5509\n",
            "Class 0 Test Accuracy: 0.839\n",
            "Class 1 Test Accuracy: 0.894\n",
            "Class 2 Test Accuracy: 0.689\n",
            "Class 3 Test Accuracy: 0.738\n",
            "Class 4 Test Accuracy: 0.735\n",
            "Class 5 Test Accuracy: 0.142\n",
            "Class 6 Test Accuracy: 0.286\n",
            "Class 7 Test Accuracy: 0.36\n",
            "Class 8 Test Accuracy: 0.35\n",
            "Class 9 Test Accuracy: 0.476\n",
            "Rare Test Accuracy: 0.3228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-47FnQRsfkM"
      },
      "source": [
        "As we can see, the test performance on the rare classes is awful. Can we rectify this issue by adding rare-class examples?"
      ],
      "id": "p-47FnQRsfkM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnDJvyMWtCCa"
      },
      "source": [
        "# Mining Rare Classes"
      ],
      "id": "JnDJvyMWtCCa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH1qtKB4tK2v"
      },
      "source": [
        "## Preparing a Query Set\n",
        "\n",
        "In this example, we know that there are rare classes in the unlabeled dataset that can help us improve the accuracy of the model. How do we select these points if we do not know *where* they are in the unlabeled dataset? Here, we use [SIMILAR](https://arxiv.org/abs/2107.00717) to select rare-class examples from the unlabeled set. SIMILAR requires access to a query set of points that it uses to choose similar unlabeled points. Hence, we must first prepare this query set.\n",
        "\n",
        "Where do we get the query set? Luckily, we already have a couple points in our training dataset to choose."
      ],
      "id": "lH1qtKB4tK2v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQupSdbrur3_"
      },
      "source": [
        "# Go over the training dataset, getting the indices of all the rare-class examples\n",
        "rare_training_example_indices = []\n",
        "for index, (_, label) in enumerate(cifar10_train):\n",
        "    if label in rare_classes:\n",
        "        rare_training_example_indices.append(index)\n",
        "\n",
        "# Create a query set that contains only the rare-class examples of the training dataset\n",
        "rare_class_query_set = Subset(cifar10_train, rare_training_example_indices)"
      ],
      "id": "MQupSdbrur3_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgvh20tYviAr"
      },
      "source": [
        "## Using DISTIL's SIMILAR Implementation: SMI\n",
        "\n",
        "Now that we have the query set, we are ready to use DISTIL's implementation of SIMILAR. In particular, we use the submodular mutual information [strategy](https://github.com/decile-team/distil/blob/main/distil/active_learning_strategies/smi.py) that is detailed in [SIMILAR](https://arxiv.org/abs/2107.00717). This will allow us to select a set of points to label within a specified budget $k$.\n",
        "\n",
        "Specifically, the strategy attempts to maximize the [submodular mutual information](https://arxiv.org/abs/2006.15412) between a subset $\\mathcal{A}$ of size no greater than $k$ of the unlabeled dataset $\\mathcal{U}$ and the query set $\\mathcal{Q}$:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{argmax}_{\\mathcal{A} \\subseteq \\mathcal{U}, |\\mathcal{A}|\\leq k} I_F(\\mathcal{A};\\mathcal{Q})\n",
        "\\end{align}\n",
        "\n",
        "where $F$ is a submodular set function."
      ],
      "id": "cgvh20tYviAr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPKl0J3HyZZO"
      },
      "source": [
        "# Define arguments for SMI\n",
        "selection_strategy_args = {'device':        args['device'],       # Use the device used in training\n",
        "                           'batch_size':    args['batch_size'],   # Use the batch size used in training\n",
        "                           'smi_function':  'fl2mi',              # Use a facility location function, which captures representation information\n",
        "                           'metric':        'cosine',             # Use cosine similarity when determining the likeness of two data points\n",
        "                           'optimizer':     'LazyGreedy'          # When doing submodular maximization, use the lazy greedy optimizer\n",
        "                          }\n",
        "\n",
        "# Create the SMI selection strategy. Note: We remove the labels from the unlabeled portion of CIFAR-10 that we created earlier.\n",
        "# In a practical application, one would not have these labels a priori.\n",
        "selection_strategy = SMI(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), rare_class_query_set, trained_model, nclasses, selection_strategy_args)\n",
        "\n",
        "# Disable the augmentations used in the training dataset. Since all augmentations come from the cifar10_full_train object, we set its transform to the \n",
        "# transform used by the test set.\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "\n",
        "# Do the selection, which will return the indices of the selected points with respect to the unlabeled dataset.\n",
        "budget = 750\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "\n",
        "# Re-enable augmentations\n",
        "cifar10_full_train.transform = cifar_training_transform"
      ],
      "id": "HPKl0J3HyZZO",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQAIxhA1dLE"
      },
      "source": [
        "## Labeling the Points\n",
        "\n",
        "Now that we know which points should be labeled, we can present them to human labelers for annotation. Here, we can do so automatically since we already know their labels for the sake of the example."
      ],
      "id": "zoQAIxhA1dLE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlQ5Fr51yS8"
      },
      "source": [
        "# Form a labeled subset of the unlabeled dataset. Again, we already have the labels, \n",
        "# so we simply take a subset. Note, however, that the selection was done without the \n",
        "# use of the labels and that we would normally not have these labels. Hence, the \n",
        "# following statement would usually require human effort to complete.\n",
        "smi_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)"
      ],
      "id": "HAlQ5Fr51yS8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zom1rZrJ2Wi_"
      },
      "source": [
        "## Characterizing the Selection\n",
        "\n",
        "Now that we have selected and labeled these new points, we can add them to the training dataset and retrain our model. Before that, how many points did we select that actually were rare-class points?"
      ],
      "id": "Zom1rZrJ2Wi_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN22GOF-2W1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cd2a54-6346-49e2-dab3-3550e0f33415"
      },
      "source": [
        "# Go over the newly labeled dataset, tallying the number of points seen in each class.\n",
        "smi_class_counts = [0 for x in range(nclasses)]\n",
        "for _, label in smi_human_labeled_dataset:\n",
        "    smi_class_counts[label] += 1\n",
        "\n",
        "# Print each class count\n",
        "for class_idx, class_count in enumerate(smi_class_counts):\n",
        "    print(F\"Class {class_idx} count: {class_count}\")\n",
        "\n",
        "# Print total rare count\n",
        "total_rare_count = sum([smi_class_counts[i] for i in rare_classes])\n",
        "print(F\"Total Rare Count: {total_rare_count}\")"
      ],
      "id": "GN22GOF-2W1M",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 47\n",
            "Class 1 count: 40\n",
            "Class 2 count: 43\n",
            "Class 3 count: 118\n",
            "Class 4 count: 81\n",
            "Class 5 count: 45\n",
            "Class 6 count: 65\n",
            "Class 7 count: 108\n",
            "Class 8 count: 74\n",
            "Class 9 count: 129\n",
            "Total Rare Count: 421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZx_yx07sEw"
      },
      "source": [
        "We were able to get a good number of rare-class points. For comparison sake, how many rare points would we get using some of DISTIL's other strategies?"
      ],
      "id": "xyZx_yx07sEw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvDNvY3D9hSn"
      },
      "source": [
        "**BADGE**"
      ],
      "id": "FvDNvY3D9hSn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_iPljF9e_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b14efa-c51d-431a-c0a8-93eb852575ef"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = BADGE(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 750\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "badge_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "badge_class_counts = [0 for x in range(nclasses)]\n",
        "for _, label in badge_human_labeled_dataset:\n",
        "    badge_class_counts[label] += 1\n",
        "\n",
        "for class_idx, class_count in enumerate(badge_class_counts):\n",
        "    print(F\"Class {class_idx} count: {class_count}\")\n",
        "\n",
        "total_rare_count = sum([badge_class_counts[i] for i in rare_classes])\n",
        "print(F\"Total Rare Count: {total_rare_count}\")"
      ],
      "id": "HN_iPljF9e_L",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 114\n",
            "Class 1 count: 92\n",
            "Class 2 count: 139\n",
            "Class 3 count: 158\n",
            "Class 4 count: 125\n",
            "Class 5 count: 16\n",
            "Class 6 count: 29\n",
            "Class 7 count: 28\n",
            "Class 8 count: 19\n",
            "Class 9 count: 30\n",
            "Total Rare Count: 122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1PDZ2qk-hi7"
      },
      "source": [
        "**Random**"
      ],
      "id": "E1PDZ2qk-hi7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4DQ3_ld-j8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34024012-f6c4-4b9b-d54c-f39f62ada803"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = RandomSampling(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 750\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "random_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "random_class_counts = [0 for x in range(nclasses)]\n",
        "for _, label in random_human_labeled_dataset:\n",
        "    random_class_counts[label] += 1\n",
        "\n",
        "for class_idx, class_count in enumerate(random_class_counts):\n",
        "    print(F\"Class {class_idx} count: {class_count}\")\n",
        "\n",
        "total_rare_count = sum([random_class_counts[i] for i in rare_classes])\n",
        "print(F\"Total Rare Count: {total_rare_count}\")"
      ],
      "id": "o4DQ3_ld-j8U",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 146\n",
            "Class 1 count: 128\n",
            "Class 2 count: 124\n",
            "Class 3 count: 142\n",
            "Class 4 count: 143\n",
            "Class 5 count: 16\n",
            "Class 6 count: 9\n",
            "Class 7 count: 14\n",
            "Class 8 count: 11\n",
            "Class 9 count: 17\n",
            "Total Rare Count: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK5KB_UH-zR2"
      },
      "source": [
        "**Entropy**"
      ],
      "id": "wK5KB_UH-zR2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncA_-JMA-zoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a424e4-65ff-4ae1-ed14-0be4caa6d978"
      },
      "source": [
        "# Repeat the previous steps\n",
        "selection_strategy = EntropySampling(cifar10_train, LabeledToUnlabeledDataset(cifar10_unlabeled), trained_model, nclasses, selection_strategy_args)\n",
        "\n",
        "cifar10_full_train.transform = cifar_test_transform\n",
        "budget = 750\n",
        "selected_idx = selection_strategy.select(budget)\n",
        "cifar10_full_train.transform = cifar_training_transform\n",
        "\n",
        "entropy_human_labeled_dataset = Subset(cifar10_unlabeled, selected_idx)\n",
        "\n",
        "entropy_class_counts = [0 for x in range(nclasses)]\n",
        "for _, label in entropy_human_labeled_dataset:\n",
        "    entropy_class_counts[label] += 1\n",
        "\n",
        "for class_idx, class_count in enumerate(entropy_class_counts):\n",
        "    print(F\"Class {class_idx} count: {class_count}\")\n",
        "\n",
        "total_rare_count = sum([entropy_class_counts[i] for i in rare_classes])\n",
        "print(F\"Total Rare Count: {total_rare_count}\")"
      ],
      "id": "ncA_-JMA-zoA",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 96\n",
            "Class 1 count: 54\n",
            "Class 2 count: 126\n",
            "Class 3 count: 168\n",
            "Class 4 count: 172\n",
            "Class 5 count: 22\n",
            "Class 6 count: 34\n",
            "Class 7 count: 34\n",
            "Class 8 count: 22\n",
            "Class 9 count: 22\n",
            "Total Rare Count: 134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvMg93--Byvl"
      },
      "source": [
        "Hence, we can see that SMI does comparatively much better at selecting rare instances."
      ],
      "id": "RvMg93--Byvl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjvhIDHsAkU1"
      },
      "source": [
        "# Improving Performance"
      ],
      "id": "vjvhIDHsAkU1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF-HsA27AsUG"
      },
      "source": [
        "## Re-Training\n",
        "\n",
        "Let us re-train our model using the newly selected points."
      ],
      "id": "eF-HsA27AsUG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kkbzgxVAkl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6669039-ea8d-47e8-a7dd-c59f4ac2c57a"
      },
      "source": [
        "# Create a new training dataset by concatenating what we have with the newly labeled points\n",
        "new_training_dataset = ConcatDataset([cifar10_train, smi_human_labeled_dataset])\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()"
      ],
      "id": "1kkbzgxVAkl7",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 102 Training accuracy: 0.992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtUxT2pBLx_"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Now, let us see the accuracy improvement."
      ],
      "id": "6PtUxT2pBLx_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xj8wmgPBP9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b46fab6-392d-43bf-da2a-ab875f437b58"
      },
      "source": [
        "# Get the full test accuracy\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")\n",
        "\n",
        "# Get the per-class test accuracies\n",
        "rare_indices = []\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    # Get the indices of the test set corresponding to this class\n",
        "    test_rare_class_subset_idx = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "    \n",
        "    if class_idx in rare_classes:\n",
        "        rare_indices.extend(test_rare_class_subset_idx)\n",
        "\n",
        "    # Get the accuracy on this class subset\n",
        "    cifar10_test_class_subset = Subset(cifar10_test, test_rare_class_subset_idx)\n",
        "\n",
        "    rare_class_test_accuracy_before = dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    rare_class_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    print(F\"Class {class_idx} Test Accuracy: {rare_class_test_accuracy_before} to {rare_class_test_accuracy_after}\")\n",
        "\n",
        "# Get accuracy on all rare points\n",
        "cifar10_test_rare_subset = Subset(cifar10_test, rare_indices)\n",
        "rare_test_accuracy_before = dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "rare_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "print(F\"Rare Test Accuracy: {rare_test_accuracy_before} to {rare_test_accuracy_after}\")"
      ],
      "id": "2Xj8wmgPBP9U",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Test Accuracy Improvement: 0.5509 to 0.6512\n",
            "Class 0 Test Accuracy: 0.839 to 0.843\n",
            "Class 1 Test Accuracy: 0.894 to 0.918\n",
            "Class 2 Test Accuracy: 0.689 to 0.649\n",
            "Class 3 Test Accuracy: 0.738 to 0.769\n",
            "Class 4 Test Accuracy: 0.735 to 0.812\n",
            "Class 5 Test Accuracy: 0.142 to 0.283\n",
            "Class 6 Test Accuracy: 0.286 to 0.441\n",
            "Class 7 Test Accuracy: 0.36 to 0.537\n",
            "Class 8 Test Accuracy: 0.35 to 0.621\n",
            "Class 9 Test Accuracy: 0.476 to 0.639\n",
            "Rare Test Accuracy: 0.3228 to 0.5042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK89JhX6Fq3s"
      },
      "source": [
        "## Comparison\n",
        "\n",
        "What would the accuracy improvement look like if we had used the other methods?"
      ],
      "id": "BK89JhX6Fq3s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxklRX4uF1UO"
      },
      "source": [
        "**BADGE**"
      ],
      "id": "jxklRX4uF1UO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0_1FoFYF8pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de94b740-7be3-4f1d-c906-145ad2bbedfc"
      },
      "source": [
        "# Repeat the process\n",
        "new_training_dataset = ConcatDataset([cifar10_train, badge_human_labeled_dataset])\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")\n",
        "\n",
        "rare_indices = []\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    test_rare_class_subset_idx = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "    \n",
        "    if class_idx in rare_classes:\n",
        "        rare_indices.extend(test_rare_class_subset_idx)\n",
        "\n",
        "    cifar10_test_class_subset = Subset(cifar10_test, test_rare_class_subset_idx)\n",
        "\n",
        "    rare_class_test_accuracy_before = dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    rare_class_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    print(F\"Class {class_idx} Test Accuracy: {rare_class_test_accuracy_before} to {rare_class_test_accuracy_after}\")\n",
        "\n",
        "cifar10_test_rare_subset = Subset(cifar10_test, rare_indices)\n",
        "rare_test_accuracy_before = dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "rare_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "print(F\"Rare Test Accuracy: {rare_test_accuracy_before} to {rare_test_accuracy_after}\")"
      ],
      "id": "X0_1FoFYF8pU",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 122 Training accuracy: 0.994\n",
            "Full Test Accuracy Improvement: 0.5509 to 0.623\n",
            "Class 0 Test Accuracy: 0.839 to 0.883\n",
            "Class 1 Test Accuracy: 0.894 to 0.941\n",
            "Class 2 Test Accuracy: 0.689 to 0.725\n",
            "Class 3 Test Accuracy: 0.738 to 0.748\n",
            "Class 4 Test Accuracy: 0.735 to 0.797\n",
            "Class 5 Test Accuracy: 0.142 to 0.276\n",
            "Class 6 Test Accuracy: 0.286 to 0.312\n",
            "Class 7 Test Accuracy: 0.36 to 0.492\n",
            "Class 8 Test Accuracy: 0.35 to 0.441\n",
            "Class 9 Test Accuracy: 0.476 to 0.615\n",
            "Rare Test Accuracy: 0.3228 to 0.4272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNArqgcGF41l"
      },
      "source": [
        "**Random**"
      ],
      "id": "gNArqgcGF41l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgD2s2lF86O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18bb26e-abcf-4e12-ae1f-b06c4f1c03a6"
      },
      "source": [
        "# Repeat the process\n",
        "new_training_dataset = ConcatDataset([cifar10_train, random_human_labeled_dataset])\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")\n",
        "\n",
        "rare_indices = []\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    test_rare_class_subset_idx = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "    \n",
        "    if class_idx in rare_classes:\n",
        "        rare_indices.extend(test_rare_class_subset_idx)\n",
        "\n",
        "    cifar10_test_class_subset = Subset(cifar10_test, test_rare_class_subset_idx)\n",
        "\n",
        "    rare_class_test_accuracy_before = dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    rare_class_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    print(F\"Class {class_idx} Test Accuracy: {rare_class_test_accuracy_before} to {rare_class_test_accuracy_after}\")\n",
        "\n",
        "cifar10_test_rare_subset = Subset(cifar10_test, rare_indices)\n",
        "rare_test_accuracy_before = dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "rare_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "print(F\"Rare Test Accuracy: {rare_test_accuracy_before} to {rare_test_accuracy_after}\")"
      ],
      "id": "xUgD2s2lF86O",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 118 Training accuracy: 0.991\n",
            "Full Test Accuracy Improvement: 0.5509 to 0.5915\n",
            "Class 0 Test Accuracy: 0.839 to 0.771\n",
            "Class 1 Test Accuracy: 0.894 to 0.932\n",
            "Class 2 Test Accuracy: 0.689 to 0.758\n",
            "Class 3 Test Accuracy: 0.738 to 0.612\n",
            "Class 4 Test Accuracy: 0.735 to 0.806\n",
            "Class 5 Test Accuracy: 0.142 to 0.232\n",
            "Class 6 Test Accuracy: 0.286 to 0.425\n",
            "Class 7 Test Accuracy: 0.36 to 0.341\n",
            "Class 8 Test Accuracy: 0.35 to 0.499\n",
            "Class 9 Test Accuracy: 0.476 to 0.539\n",
            "Rare Test Accuracy: 0.3228 to 0.4072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkcyKstqF5Ml"
      },
      "source": [
        "**Entropy**"
      ],
      "id": "SkcyKstqF5Ml"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlB34d8fF9bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70509857-c0c0-4eee-cf5a-efb65f148782"
      },
      "source": [
        "# Repeat the process\n",
        "new_training_dataset = ConcatDataset([cifar10_train, entropy_human_labeled_dataset])\n",
        "new_dt = data_train(new_training_dataset, copy.deepcopy(net), args)\n",
        "new_trained_model = new_dt.train()\n",
        "\n",
        "full_test_accuracy_before = dt.get_acc_on_set(cifar10_test)\n",
        "full_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test)\n",
        "\n",
        "print(F\"Full Test Accuracy Improvement: {full_test_accuracy_before} to {full_test_accuracy_after}\")\n",
        "\n",
        "rare_indices = []\n",
        "for class_idx in range(nclasses):\n",
        "\n",
        "    test_rare_class_subset_idx = torch.where(torch.Tensor(cifar10_test.targets) == class_idx)[0].cpu().numpy()\n",
        "    \n",
        "    if class_idx in rare_classes:\n",
        "        rare_indices.extend(test_rare_class_subset_idx)\n",
        "\n",
        "    cifar10_test_class_subset = Subset(cifar10_test, test_rare_class_subset_idx)\n",
        "\n",
        "    rare_class_test_accuracy_before = dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    rare_class_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_class_subset)\n",
        "    print(F\"Class {class_idx} Test Accuracy: {rare_class_test_accuracy_before} to {rare_class_test_accuracy_after}\")\n",
        "\n",
        "cifar10_test_rare_subset = Subset(cifar10_test, rare_indices)\n",
        "rare_test_accuracy_before = dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "rare_test_accuracy_after = new_dt.get_acc_on_set(cifar10_test_rare_subset)\n",
        "print(F\"Rare Test Accuracy: {rare_test_accuracy_before} to {rare_test_accuracy_after}\")"
      ],
      "id": "nlB34d8fF9bP",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training..\n",
            "Epoch: 116 Training accuracy: 0.993\n",
            "Full Test Accuracy Improvement: 0.5509 to 0.6483\n",
            "Class 0 Test Accuracy: 0.839 to 0.879\n",
            "Class 1 Test Accuracy: 0.894 to 0.906\n",
            "Class 2 Test Accuracy: 0.689 to 0.699\n",
            "Class 3 Test Accuracy: 0.738 to 0.769\n",
            "Class 4 Test Accuracy: 0.735 to 0.829\n",
            "Class 5 Test Accuracy: 0.142 to 0.182\n",
            "Class 6 Test Accuracy: 0.286 to 0.456\n",
            "Class 7 Test Accuracy: 0.36 to 0.457\n",
            "Class 8 Test Accuracy: 0.35 to 0.623\n",
            "Class 9 Test Accuracy: 0.476 to 0.683\n",
            "Rare Test Accuracy: 0.3228 to 0.4802\n"
          ]
        }
      ]
    }
  ]
}